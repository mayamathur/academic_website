[{"authors":["admin"],"categories":null,"content":"I am an Instructor at Stanford University\u0026rsquo;s Quantitative Sciences Unit, conducting both original statistical research and applied research. My publication list is available on Google Scholar, and repositories with data, code, and materials for my research are available on the Open Science Framework.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://mayamathur.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I am an Instructor at Stanford University\u0026rsquo;s Quantitative Sciences Unit, conducting both original statistical research and applied research. My publication list is available on Google Scholar, and repositories with data, code, and materials for my research are available on the Open Science Framework.","tags":null,"title":"Maya B. Mathur","type":"author"},{"authors":["Maya B. Mathur","Thomas N. Robinson","David B. Reichling","Christopher Gardner","Janice Nadler","Paul A. Bain","Jacob Peacock"],"categories":[],"content":"","date":1577449011,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577449011,"objectID":"7944606938bc24f7925c70f3e8f968d9","permalink":"https://mayamathur.github.io/publication/awrp/","publishdate":"2019-12-27T08:16:51-04:00","relpermalink":"/publication/awrp/","section":"publication","summary":"","tags":[],"title":"Reducing meat consumption by appealing to animal welfare: Protocol for a meta-analysis and theoretical review","type":"publication"},{"authors":["Maya B. Mathur","Tyler J. VanderWeele"],"categories":[],"content":"","date":1576844211,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576844211,"objectID":"646d132c6b2078ba34e68ca7b2c930d2","permalink":"https://mayamathur.github.io/publication/sapbe/","publishdate":"2019-12-20T08:16:51-04:00","relpermalink":"/publication/sapbe/","section":"publication","summary":"","tags":[],"title":"Estimating publication bias in meta-analyses: A meta-meta-analysis across disciplines and journal tiers","type":"publication"},{"authors":["Maya B. Mathur","Tyler J. VanderWeele"],"categories":[],"content":"","date":1572869811,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572869811,"objectID":"71511bc6eddca89a49b073d37ff1dfa4","permalink":"https://mayamathur.github.io/publication/eva/","publishdate":"2019-11-04T08:16:51-04:00","relpermalink":"/publication/eva/","section":"publication","summary":"","tags":[],"title":"A simple, interpretable conversion from Pearson’s correlation to Cohen’s d for continuous exposures","type":"publication"},{"authors":["Maya B. Mathur","Tyler J. VanderWeele"],"categories":[],"content":"","date":1572178611,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572178611,"objectID":"71d63e78ee9c56cd4f47079e8be3a162","permalink":"https://mayamathur.github.io/publication/hedges/","publishdate":"2019-10-27T08:16:51-04:00","relpermalink":"/publication/hedges/","section":"publication","summary":"Psychological scientists are now trying to replicate published research from scratch to confirm the findings. In an increasingly widespread replication study design, each of several collaborating sites (such as universities) independently tries to replicate an original study, and the results are synthesized across sites. Hedges and Schauer (2019) proposed statistical analyses for these replication projects; their analyses focus on assessing the extent to which results differ across the replication sites, by testing for heterogeneity among a set of replication studies, while excluding the original study. We agree with their premises regarding the limitations of existing analysis methods and regarding the importance of accounting for heterogeneity among the replications. This objective may be interesting in its own right. However, we argue that by focusing only on whether the replication studies have similar effect sizes to one another, these analyses are not particularly appropriate for assessing whether the replications in fact support the scientific effect under investigation or for assessing the power of multisite replication projects. We reanalyze Hedges and Schauer’s (2019) example dataset using alternative metrics of replication success that directly address these objectives. We reach a more optimistic conclusion regarding replication success than they did, illustrating that the alternative metrics can lead to quite different conclusions from those of Hedges and Schauer (2019).","tags":[],"title":"Challenges and suggestions for defining replication \"success\" when effects may be heterogeneous: Comment on Hedges and Schauer (2019)","type":"publication"},{"authors":["Maya B. Mathur","Tyler J. VanderWeele"],"categories":[],"content":"","date":1569586611,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569586611,"objectID":"cb93a8d841ba00707bcb18011c84b741","permalink":"https://mayamathur.github.io/publication/metawars/","publishdate":"2019-09-27T08:16:51-04:00","relpermalink":"/publication/metawars/","section":"publication","summary":"Independent meta-analyses on the same topic can sometimes yield seemingly conflicting results. For example, prominent meta-analyses assessing the effects of violent video games on aggressive behavior have reached apparently different conclusions, provoking ongoing debate. We suggest that such conflicts are sometimes partly an artifact of reporting practices for meta-analyses that focus only on the pooled point estimate and its statistical significance. Considering statistics that focus on the distributions of effect sizes and that adequately characterize effect heterogeneity can sometimes indicate reasonable consensus between “warring” meta-analyses. Using novel analyses, we show that this seems to be the case in the video-game literature. Despite seemingly conflicting results for the statistical significance of the pooled estimates in different meta-analyses of video-game studies, all of the meta-analyses do in fact point to the conclusion that, in the vast majority of settings, violent video games do increase aggressive behavior but that these effects are almost always quite small.","tags":[],"title":"Finding common ground in meta-analysis \"wars\" on violent video games","type":"publication"},{"authors":["Maya B. Mathur","David B. Reichling","Francesca Lunardini","Alice Geminiani","Alberto Antonietti","Peter A. M. Ruijten","Carmel Levitan","Gideon Nave","Dylan Manfredi","Brandy Bessette-Symons","Attila Szuts","Balazs Aczel"],"categories":[],"content":"","date":1556972211,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556972211,"objectID":"36b618f16134ab91822d3a238026c461","permalink":"https://mayamathur.github.io/publication/uv3/","publishdate":"2019-05-04T08:16:51-04:00","relpermalink":"/publication/uv3/","section":"publication","summary":"Android robots that are close, but imperfect, likenesses of humans can provoke negative feelings of dislike and eeriness in humans (“Uncanny Valley” effect). We investigated whether category confusion between the perceptual categories of “robot” and “human” contributes to Uncanny Valley aversion. Using a novel, validated corpus of 182 images of real robot and human faces, we precisely estimated the shape of the Uncanny Valley and the location of the perceived robot/human boundary. To implicitly measure confusion, we tracked 358 subjects’ mouse trajectories as they categorized the faces. We observed a clear Uncanny Valley and a pattern of categorization supporting a perceived categorical boundary. Yet, in contrast to predictions of the category confusion mechanism hypothesis, the Uncanny Valley and category boundary locations did not coincide, and mediation analyses further failed to support a causal role of category confusion. These results suggest category confusion does not explain the Uncanny Valley effect.","tags":[],"title":"Uncanny but not confusing:  Multisite study of perceptual category confusion in the Uncanny Valley","type":"publication"},{"authors":["Maya B. Mathur","Tyler J. VanderWeele"],"categories":[],"content":"","date":1553689011,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553689011,"objectID":"cc93ed564def0cda3c0329f8febed5df","permalink":"https://mayamathur.github.io/publication/sapb/","publishdate":"2019-03-27T08:16:51-04:00","relpermalink":"/publication/sapb/","section":"publication","summary":"We propose sensitivity analyses for publication bias in meta-analyses. We consider a publication process such that “statistically significant” results are more likely to be published than negative or “nonsignificant” results by an unknown ratio, eta. Using inverse-probability weighting and robust estimation that accommodates non-normal true effects, small meta-analyses, and clustering, we develop sensitivity analyses that enable statements such as: “For publication bias to shift the observed point estimate to the null, ‘significant’ results would need to be at least 30-fold more likely to be published than negative or ‘nonsignificant' results.” Comparable statements can be made regarding shifting to a chosen non-null value or shifting the confidence interval. To aid interpretation, we describe empirical benchmarks for plausible values of eta across disciplines. We show that a worst-case meta-analytic point estimate for maximal publication bias under the selection model can be obtained simply by conducting a standard meta-analysis of only the negative and “nonsignificant” studies; this method sometimes indicates that no amount of such publication bias could “explain away” the results. We illustrate the proposed methods using real-life meta-analyses and provide an R package, PublicationBias.","tags":[],"title":"Sensitivity analysis for publication bias in meta-analyses","type":"publication"},{"authors":["Maya B. Mathur","Tyler J. VanderWeele"],"categories":[],"content":"","date":1524313011,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524313011,"objectID":"2c6a97ab14bb68c7073ca4b95bd9d5ee","permalink":"https://mayamathur.github.io/publication/rrr/","publishdate":"2018-04-21T08:16:51-04:00","relpermalink":"/publication/rrr/","section":"publication","summary":"","tags":[],"title":"New statistical metrics for multisite replication projects","type":"publication"},{"authors":null,"categories":null,"content":"","date":1493276400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493276400,"objectID":"f606457c7de59312b878abc0d85e3bb7","permalink":"https://mayamathur.github.io/project/external-project/qualtricsmousetracker/","publishdate":"2017-04-27T00:00:00-07:00","relpermalink":"/project/external-project/qualtricsmousetracker/","section":"project","summary":"Software in R, Javascript, and Qualtrics to design and analyze psychology experiments that use fine-grained mouse-tracking measures of perceptual category competition.","tags":["R","Javascript","Qualtrics","Psychology"],"title":"Qualtrics Mousetracker","type":"project"},{"authors":null,"categories":null,"content":"","date":925196400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":925196400,"objectID":"65d0cf5c990506cd5c1139aef1d972bb","permalink":"https://mayamathur.github.io/project/external-project/publicationbias/","publishdate":"1999-04-27T00:00:00-07:00","relpermalink":"/project/external-project/publicationbias/","section":"project","summary":"Conducts sensitivity analysis for publication bias in meta-analyses.","tags":["R","Statistics"],"title":"R package PublicationBias","type":"project"},{"authors":null,"categories":null,"content":"","date":862124400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":862124400,"objectID":"a4633329533d8489fa9e3a3945ca8b6c","permalink":"https://mayamathur.github.io/project/external-project/metautility/","publishdate":"1997-04-27T00:00:00-07:00","relpermalink":"/project/external-project/metautility/","section":"project","summary":"Contains functions to estimate the proportion of effects stronger than a threshold of scientific importance, to make effect size conversions, and to compute and format estimates and inference.","tags":["R","Statistics"],"title":"R package MetaUtility","type":"project"},{"authors":null,"categories":null,"content":"","date":830588400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":830588400,"objectID":"861c2b23249f92100e2dee2c3bd4cbe3","permalink":"https://mayamathur.github.io/project/external-project/evalue/","publishdate":"1996-04-27T00:00:00-07:00","relpermalink":"/project/external-project/evalue/","section":"project","summary":"Conducts sensitivity analysis for unmeasured confounding for observational studies and meta-analysis, and conducts analogous sensitivity analyses for selection bias.","tags":["R","Statistics"],"title":"R package EValue","type":"project"},{"authors":null,"categories":null,"content":"","date":830588400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":830588400,"objectID":"bcd88a61f846b8de3ca3aae0cb806e8d","permalink":"https://mayamathur.github.io/project/external-project/evaluestata/","publishdate":"1996-04-27T00:00:00-07:00","relpermalink":"/project/external-project/evaluestata/","section":"project","summary":"Calculates the E-value, a measure of sensitivity to unmeasured confounding.","tags":["Stata","Statistics"],"title":"Stata module EVALUE","type":"project"},{"authors":null,"categories":null,"content":"","date":798966000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":798966000,"objectID":"973f41cccf2c48c5de4dc055a055acfa","permalink":"https://mayamathur.github.io/project/external-project/evaluewebsite/","publishdate":"1995-04-27T00:00:00-07:00","relpermalink":"/project/external-project/evaluewebsite/","section":"project","summary":"Calculates the E-value, a measure of sensitivity to unmeasured confounding.","tags":["Statistics","GUI"],"title":"E-value calculator website","type":"project"},{"authors":null,"categories":null,"content":"","date":735894000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":735894000,"objectID":"4b30fcf3ac8a027f91fb42781eaaa229","permalink":"https://mayamathur.github.io/project/external-project/nrejections/","publishdate":"1993-04-27T00:00:00-07:00","relpermalink":"/project/external-project/nrejections/","section":"project","summary":"Computes metrics of outcome-wide evidence strength for studies testing multiple correlated outcomes.","tags":["R","Statistics"],"title":"R package NRejections","type":"project"},{"authors":null,"categories":null,"content":"","date":672735600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":672735600,"objectID":"2868acbb79b1889434e5a35c0abdf9e2","permalink":"https://mayamathur.github.io/project/external-project/replicate/","publishdate":"1991-04-27T00:00:00-07:00","relpermalink":"/project/external-project/replicate/","section":"project","summary":"Conducts statistical analyses for multisite replication projects.","tags":["R","Statistics"],"title":"R package Replicate","type":"project"},{"authors":null,"categories":null,"content":"","date":641199600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":641199600,"objectID":"ff31f8d65981e5a2189a54db01660c0c","permalink":"https://mayamathur.github.io/project/external-project/simtimevar/","publishdate":"1990-04-27T00:00:00-07:00","relpermalink":"/project/external-project/simtimevar/","section":"project","summary":"Simulates a longitudinal dataset with time-varying covariates with user-specified correlation structure.","tags":["R","Statistics"],"title":"R package SimTimeVar","type":"project"}]